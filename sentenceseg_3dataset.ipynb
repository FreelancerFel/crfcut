{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data/checkpoint; unzip ted_fake.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from @bact at https://colab.research.google.com/drive/1hdtmwTXHLrqNmDhDqHnTQGpDVy1aJc4t\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pycrfsuite\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.tag import pos_tag\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_rows', 10)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchid = pd.read_csv('data/orchid_corpus/orchid97.crp.utf',sep='\\t',header=None)\n",
    "orchid.columns = ['text']\n",
    "#remove weird words\n",
    "orchid['first_char'] = orchid.text.map(lambda x: x[0])\n",
    "orchid = orchid[(orchid.first_char!='%')&(orchid.first_char!='#')][['text']]\n",
    "#get word,pos\n",
    "orchid['word'] = orchid.text.map(lambda x: x.split('/')[0])\n",
    "orchid['word'] = orchid.word.map(lambda x: ' ' if (x=='<space>')|(x=='') else x)\n",
    "orchid['pos'] = orchid.text.map(lambda x: x.split('/')[1] if len(x.split('/'))==2 else None)\n",
    "#labels\n",
    "orchid['lab'] = orchid.apply(lambda row: 'E' if row['text']=='//' else 'I',1)\n",
    "orchid = orchid[(orchid.lab=='E')|(~orchid.pos.isna())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 ms, sys: 371 ms, total: 373 ms\n",
      "Wall time: 371 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ted_all_sentences = np.load('data/checkpoint/ted-all-sentences.npy') \n",
    "fake_review_all_sentences = np.load('data/checkpoint/fake-review-all-sentences.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from 3 datasets\n",
    "np.random.seed(42)\n",
    "ratio = .25\n",
    "ted_sample = np.random.choice(ted_all_sentences, int(len(ted_all_sentences) * ratio))\n",
    "orchid_sample = orchid.iloc[:int(len(orchid) * ratio)]\n",
    "fake_review_sample = np.random.choice(fake_review_all_sentences, int(len(fake_review_all_sentences) * ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of TED: 385\n",
      "Length of orchid: 91453\n",
      "Length of fake review: 54370\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of TED: {len(ted_sample)}\")\n",
    "print(f\"Length of orchid: {len(orchid_sample)}\")\n",
    "print(f\"Length of fake review: {len(fake_review_sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_word_lab(all_sentences):\n",
    "    all_tuples = []\n",
    "    # all_tuples = np.array([])\n",
    "    for i in tqdm(range(len(all_sentences)), total=len(all_sentences)):\n",
    "        tuples = []\n",
    "        # tuples = np.array()\n",
    "        for s in all_sentences[i].split('|'):\n",
    "            s_lst = word_tokenize(s)\n",
    "            for j in range(len(s_lst)):\n",
    "                lab = 'E' if j==len(s_lst)-1 else 'I'\n",
    "                tuples.append((s_lst[j],lab))\n",
    "        all_tuples.append(tuples)\n",
    "        # all_tuples = np.append(all_tuples, tuples)\n",
    "    return all_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:09<00:00, 40.72it/s]\n",
      "100%|██████████| 54370/54370 [00:42<00:00, 1269.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 884 ms, total: 1min 3s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ted_all_tuples = assign_word_lab(ted_sample)\n",
    "orchid_all_tuples = [(row['word'],row['lab']) for i,row in orchid_sample.iterrows()]\n",
    "fake_review_all_tuples = assign_word_lab(fake_review_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enders = [\"ครับ\",\"ค่ะ\",\"คะ\",\"นะคะ\",\"นะ\",\"จ้ะ\",\"จ้า\",\"จ๋า\",\"ฮะ\", #ending honorifics\n",
    "          #enders\n",
    "          \"ๆ\",\"ได้\",\"แล้ว\",\"ด้วย\",\"เลย\",\"มาก\",\"น้อย\",\"กัน\",\"เช่นกัน\",\"เท่านั้น\",\n",
    "          \"อยู่\",\"ลง\",\"ขึ้น\",\"มา\",\"ไป\",\"ไว้\",\"เอง\",\"อีก\",\"ใหม่\",\"จริงๆ\",\n",
    "          \"บ้าง\",\"หมด\",\"ทีเดียว\",\"เดียว\",\n",
    "          #demonstratives\n",
    "          \"นั้น\",\"นี้\",\"เหล่านี้\",\"เหล่านั้น\",\n",
    "          #questions\n",
    "          \"อย่างไร\",\"ยังไง\",\"หรือไม่\",\"มั้ย\",\"ไหน\",\"อะไร\",\"ทำไม\",\"เมื่อไหร่\"]\n",
    "starters = [\"ผม\",\"ฉัน\",\"ดิฉัน\",\"ชั้น\",\"คุณ\",\"มัน\",\"เขา\",\"เค้า\",\n",
    "            \"เธอ\",\"เรา\",\"พวกเรา\",\"พวกเขา\", #pronouns\n",
    "            #connectors\n",
    "            \"และ\",\"หรือ\",\"แต่\",\"เมื่อ\",\"ถ้า\",\"ใน\",\n",
    "            \"ด้วย\",\"เพราะ\",\"เนื่องจาก\",\"ซึ่ง\",\"ไม่\",\n",
    "            \"ตอนนี้\",\"ทีนี้\",\"ดังนั้น\",\"เพราะฉะนั้น\",\"ฉะนั้น\",\n",
    "            \"ตั้งแต่\",\"ในที่สุด\",\n",
    "            #demonstratives\n",
    "            \"นั้น\",\"นี้\",\"เหล่านี้\",\"เหล่านั้น\"]\n",
    "\n",
    "def extract_features(doc, window=2, max_n_gram=3):\n",
    "    doc_features = []\n",
    "    #paddings for word and POS\n",
    "    doc = ['xxpad' for i in range(window)] + doc + ['xxpad' for i in range(window)]\n",
    "    doc_ender = []\n",
    "    doc_starter = []\n",
    "    #add enders\n",
    "    for i in range(len(doc)):\n",
    "        if doc[i] in enders:\n",
    "            doc_ender.append('ender')\n",
    "        else:\n",
    "            doc_ender.append('normal')\n",
    "    #add starters\n",
    "    for i in range(len(doc)):\n",
    "        if doc[i] in starters:\n",
    "            doc_starter.append('starter')\n",
    "        else:\n",
    "            doc_starter.append('normal')\n",
    "    #for each word\n",
    "    for i in range(window, len(doc)-window):\n",
    "        #bias term\n",
    "        word_features = ['bias'] \n",
    "        \n",
    "        #ngram features\n",
    "        for n_gram in range(1, min(max_n_gram+1,2+window*2)):\n",
    "            for j in range(i-window,i+window+2-n_gram):\n",
    "                feature_position = f'{n_gram}_{j-i}_{j-i+n_gram}'\n",
    "                word_ = f'{\"|\".join(doc[j:(j+n_gram)])}'\n",
    "                word_features += [f'word_{feature_position}={word_}']\n",
    "                ender_ =  f'{\"|\".join(doc_ender[j:(j+n_gram)])}'\n",
    "                word_features += [f'ender_{feature_position}={ender_}']\n",
    "                starter_ =  f'{\"|\".join(doc_starter[j:(j+n_gram)])}'\n",
    "                word_features += [f'starter_{feature_position}={starter_}']\n",
    "        \n",
    "        #append to feature per word\n",
    "        doc_features.append(word_features)\n",
    "    return doc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:00<00:00, 2742.15it/s]\n",
      "100%|██████████| 385/385 [00:00<00:00, 2698.12it/s]\n",
      "100%|██████████| 385/385 [00:27<00:00, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.3 s, sys: 1.16 s, total: 27.5 s\n",
      "Wall time: 27.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ted\n",
    "#target\n",
    "ted_y = []\n",
    "for t in tqdm(ted_all_tuples, total=len(ted_all_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(l)\n",
    "    ted_y.append(temp)\n",
    "\n",
    "#features\n",
    "ted_x_pre = []\n",
    "for t in tqdm(ted_all_tuples, total=len(ted_all_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(w)\n",
    "    ted_x_pre.append(temp)\n",
    "ted_x = []\n",
    "for x_ in tqdm(ted_x_pre, total=len(ted_x_pre)):\n",
    "    ted_x.append(extract_features(x_, window=2, max_n_gram = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91453/91453 [00:00<00:00, 1539641.58it/s]\n",
      "100%|██████████| 91453/91453 [00:00<00:00, 1557521.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 s, sys: 148 ms, total: 3.15 s\n",
      "Wall time: 3.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# orchid\n",
    "#target\n",
    "orchid_y = []\n",
    "for (w, l) in tqdm(orchid_all_tuples, total=len(orchid_all_tuples)):\n",
    "    orchid_y.append(l)\n",
    "#features\n",
    "orchid_x_pre = []\n",
    "for (w, l) in tqdm(orchid_all_tuples, total=len(orchid_all_tuples)):\n",
    "    orchid_x_pre.append(w)\n",
    "orchid_x = extract_features(orchid_x_pre, window=2, max_n_gram = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54370/54370 [00:00<00:00, 68578.92it/s]\n",
      "100%|██████████| 54370/54370 [00:00<00:00, 64152.16it/s]\n",
      "100%|██████████| 54370/54370 [03:45<00:00, 241.00it/s]  \n"
     ]
    }
   ],
   "source": [
    "# fake review\n",
    "#target\n",
    "fake_review_y = []\n",
    "for t in tqdm(fake_review_all_tuples, total=len(fake_review_all_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(l)\n",
    "    fake_review_y.append(temp)\n",
    "\n",
    "#features\n",
    "fake_review_x_pre = []\n",
    "for t in tqdm(fake_review_all_tuples, total=len(fake_review_all_tuples)):\n",
    "    temp = []\n",
    "    for (w, l) in t:\n",
    "        temp.append(w)\n",
    "    fake_review_x_pre.append(temp)\n",
    "fake_review_x = []\n",
    "for x_ in tqdm(fake_review_x_pre, total=len(fake_review_x_pre)):\n",
    "    fake_review_x.append(extract_features(x_, window=2, max_n_gram = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set at 80/20 proportion\n",
    "ted_x_train, ted_x_test, ted_y_train, ted_y_test = train_test_split(ted_x, ted_y, test_size=0.2, random_state=1412)\n",
    "idx = int(len(orchid_x)*0.8)\n",
    "orchid_x_train, orchid_x_test = orchid_x[:idx], orchid_x[idx:]\n",
    "orchid_y_train, orchid_y_test = orchid_y[:idx], orchid_y[idx:]\n",
    "fake_review_x_train, fake_review_x_test, fake_review_y_train, fake_review_y_test = \\\n",
    "    train_test_split(fake_review_x, fake_review_y, test_size=0.2, random_state=1412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model\n",
    "trainer = pycrfsuite.Trainer(verbose=True)\n",
    "\n",
    "for xseq, yseq in tqdm(zip(ted_x_train, ted_y_train), total=len(ted_y_train)):\n",
    "    trainer.append(xseq, yseq)\n",
    "    \n",
    "trainer.append(orchid_x_train, orchid_y_train)\n",
    "\n",
    "for xseq, yseq in tqdm(zip(fake_review_x_train, fake_review_y_train), total=len(fake_review_y_train)):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1,\n",
    "    'c2': 0,\n",
    "    'max_iterations': 1000,\n",
    "    'feature.possible_transitions': True,\n",
    "})\n",
    "\n",
    "trainer.train('models/datasets-crf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:10<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate TED dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.68      0.76      0.72      6990\n",
      "           I       0.99      0.98      0.99    155115\n",
      "\n",
      "    accuracy                           0.97    162105\n",
      "   macro avg       0.84      0.87      0.85    162105\n",
      "weighted avg       0.98      0.97      0.98    162105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ted\n",
    "# Predict (using test set)\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('models/datasets-crf.model')\n",
    "# y_pred = [tagger.tag(xseq) for xseq in x_test]\n",
    "y_pred = []\n",
    "for xseq in tqdm(ted_x_test, total=len(ted_x_test)):\n",
    "    y_pred.append(tagger.tag(xseq))\n",
    "\n",
    "# Evaluate at word-level\n",
    "labels = {'E': 0, \"I\": 1} # classification_report() needs values in 0s and 1s\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in ted_y_test for tag in row])\n",
    "\n",
    "print(\"Validate TED dataset\")\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"E\", \"I\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate orchid dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.76      0.63      0.69      1179\n",
      "           I       0.97      0.99      0.98     17112\n",
      "\n",
      "    accuracy                           0.96     18291\n",
      "   macro avg       0.87      0.81      0.83     18291\n",
      "weighted avg       0.96      0.96      0.96     18291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# orchid\n",
    "# Predict (using test set)\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('models/datasets-crf.model')\n",
    "y_pred = tagger.tag(orchid_x_test)\n",
    "\n",
    "# Evaluate at word-level\n",
    "labels = {'E': 0, \"I\": 1} # classification_report() needs values in 0s and 1s\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in orchid_y_test for tag in row])\n",
    "\n",
    "print(\"Validate orchid dataset\")\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"E\", \"I\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10874/10874 [00:58<00:00, 187.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate TED dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.98      0.96      0.97     48984\n",
      "           I       1.00      1.00      1.00    663897\n",
      "\n",
      "    accuracy                           1.00    712881\n",
      "   macro avg       0.99      0.98      0.98    712881\n",
      "weighted avg       1.00      1.00      1.00    712881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fake review\n",
    "# Predict (using test set)\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('models/datasets-crf.model')\n",
    "# y_pred = [tagger.tag(xseq) for xseq in x_test]\n",
    "y_pred = []\n",
    "for xseq in tqdm(fake_review_x_test, total=len(fake_review_x_test)):\n",
    "    y_pred.append(tagger.tag(xseq))\n",
    "\n",
    "# Evaluate at word-level\n",
    "labels = {'E': 0, \"I\": 1} # classification_report() needs values in 0s and 1s\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in fake_review_y_test for tag in row])\n",
    "\n",
    "print(\"Validate TED dataset\")\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"E\", \"I\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
